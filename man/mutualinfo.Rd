% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mutualinfo.R
\name{mutualinfo}
\alias{mutualinfo}
\title{Calculate mutual information between groups of joint variates}
\usage{
mutualinfo(
  Y1names,
  Y2names,
  X = NULL,
  learnt,
  tails = NULL,
  n = NULL,
  unit = "Sh",
  parallel = NULL,
  silent = FALSE
)
}
\arguments{
\item{Y1names}{Character vector: first group of joint variates}

\item{Y2names}{Character vector or NULL: second group of joint variates}

\item{X}{Matrix or data.frame or NULL: values of some variates conditional on which we want the probabilities.}

\item{learnt}{Either a character with the name of a directory or full path
for an 'learnt.rds' object, or such an object itself.}

\item{tails}{Named vector or list, or \code{NULL} (default). The names must match some or all of the variates in arguments \code{X}. For variates in this list, the probability conditional is understood in an semi-open interval sense: \verb{X ≤ x} or \verb{X ≥ x}, an so on. See analogous argument in \code{\link[=Pr]{Pr()}}.}

\item{n}{Integer or \code{NULL} (default): number of samples from which to approximately calculate the mutual information. Default as many as Monte Carlo samples in \code{learnt}.}

\item{unit}{Either one of 'Sh' for \emph{shannon} (default), 'Hart' for \emph{hartley}, 'nat' for \emph{natural unit}, or a positive real indicating the base of the logarithms to be used.}

\item{parallel}{Logical or \code{NULL} or positive integer: \code{TRUE}: use roughly half of available cores; \code{FALSE}: use serial computation; \code{NULL}: don't do anything (use pre-registered condition); integer: use this many cores. Default \code{NULL}}

\item{silent}{Logical: give warnings or updates in the computation?}
}
\value{
A list consisting of the elements \code{MI}, \code{CondEn12}, \code{CondEn21}, \code{En1}, \code{En2}, \code{rGauss}, \code{unit}, \code{Y1names}, \code{Y1names}. All elements except \code{unit}, \code{Y1names}, \code{Y2names} are a vector of \code{value} and \code{accuracy}. Element \code{MI} is the mutual information between (joint) variates \code{Y1names} and (joint) variates \code{Y2names}. Element\code{CondEn12} is the conditional entropy of the first variate given the second, and vice versa for \code{CondEn21}. Elements \code{En1} and \code{En1} are the (differential) entropies of the first and second variates. Elements \code{unit}, \code{Y1names}, \code{Y2names} are identical to the same inputs. Element \code{rGauss} is the absolute value of the Pearson correlation coefficient of a \emph{multivariate Gaussian distribution} having mutual information \code{MI} (the two are related by \code{MI = -log(1 - rGauss^2)/2}); it may provide a vague intuition for the \code{MI} value for people more familiar with Pearson's correlation, but should be taken with a grain of salt.
}
\description{
This function calculates various entropic information measures of two variates (each variate may consist of joint variates): the mutual information, the conditional entropies, and the entropies.
}
