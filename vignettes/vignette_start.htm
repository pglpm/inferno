<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Example of use: inferno for penguins</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Example of use: inferno for penguins</h1>



<div id="a-crash-course-in-population-inference" class="section level2">
<h2>A crash course in population inference</h2>
<div id="population-inferences" class="section level3">
<h3>Population inferences</h3>
<p>A very common type of inference is the following. We have a large or
potentially infinite group of entities, each having a set of
characteristics. Having checked the characteristics of several entities
from this group, we want to make guesses about the characteristics of
new entities from the same group.</p>
<p>The description just given is very generic or even vague. Indeed it
can be applied to a huge variety of situations.</p>
<ul>
<li>The ‘entities’ could be: objects, like electronic components; or
people, or animals, or plants, or events of some kind.</li>
<li>The characteristics could be: the material the object is made of,
and the result of some test made on it; or the age, blood-test results,
and disease condition of the person; or the species and body mass of the
animal; or the length of the petals of the flower.</li>
<li>The group could be: electronic components coming out of a particular
production line; or people of a given nationality and with given
symptoms; or animals from a particular island; or flowers of a specific
genus or family.</li>
</ul>
<p>The possibilities are endless.</p>
<p>Also the kinds of guesses that we want to make can be very diverse.
We might want to guess all characteristics of a new entity; or, having
checked <em>some</em> characteristics of a new entity, we want to guess
the ones that we haven’t or can’t check. Important examples of this kind
of inference appear in medicine. For example we may have a group defined
as follows:</p>
<ul>
<li><em>Group</em>: people from a given nationality, suffering from one
of two possible diseases.</li>
</ul>
<p>And we may consider these characteristics:</p>
<ul>
<li><em>Characteristics</em>: age; sex; weight; presence or absence of a
particular genetic factor; symptoms from a specific set of possible
ones; results from clinical tests taken at different times; kind of
disease.</li>
</ul>
<p>We observed as many as possible of these characteristics in a sample
of people from this group. Now a new person from the same group appears
in front of us. We check this person’s age, sex, weight, symptoms. We
need to guess which of the two diseases affects this person.</p>
<p><br />
The kind of inference summarily described above has one important
aspect. Suppose you have collected a sample from your group of interest,
and you want to use this sample to make guesses about new entities from
the same group. If someone exchanged one entity in your sample with
another one <em>unsystematically</em> chosen from the group, then you
wouldn’t protest. After all, you still have the same number of samples
from the same group. This aspect is called
<strong>exchangeability</strong>: we say that this kind of inference is
exchangeable. There are kinds of inference for which this aspect is not
true. For example, suppose you’re given some stock data from four
consecutive days, and you want to make guesses about the next day. If
someone replaced any of your four datapoints with a datapoint an
unsystematically chosen other day of the year, then you would protest:
the time order of the datapoints matter. This is an example of
non-exchangeable inference.</p>
<p>The inferences for which <em>inferno</em> is designed are
exchangeable ones. We shall also call them <strong>population
inferences</strong>.</p>
<p><br />
Having discussed these simple examples, let’s agree on some more
standard terminology. Let’s call:</p>
<ul>
<li><strong>Population</strong>: what we’ve called ‘group’.</li>
<li><strong>Unit</strong>: what we’ve called ‘entity’ – the object,
person, animal, etc.</li>
<li><strong>Variate</strong>: what we’ve called ‘characteristic’.</li>
</ul>
<p><br />
</p>
</div>
<div id="probability-and-population-frequencies" class="section level3">
<h3>Probability and population frequencies</h3>
<p>We have been speaking about “making guesses”; but what does this
mean?</p>
<p>When a unit is chosen unsystematically from a population, it’s only
in rare situations that we may be sure about the variates of this unit
before checking them. Suppose for instance that the population of
interest is ‘all adults from a given country’; and the variates of
interest are <code>sex</code>, <code>weight</code>, <code>height</code>.
If a person is chosen from this population, we can’t be sure beforehand
of how tall this person will be. We can exclude values like 4 m or
20 cm, but we’ll be uncertain about many other possible values. Even if
someone tells us the sex and weight of this person, we’ll still be in
doubt, but maybe we can consider some values more probable than
others.</p>
<p>That’s the keyword: <strong>probability</strong>. Although we are
unsure about a variate of a unit, we can still find some values more
probable than others: we may consider it more probable that the person
is 160 cm tall than 180 cm tall; or in a clinical inference we may
consider it more probable that the patient has a particular virus than
not.</p>
<p>Probability is our <em>degree of belief</em> about the value of the
unknown variate.</p>
<p>Note that probability is not a physical property of the unit. For
instance, the person in question may be exactly 158 cm tall; the
probability of being 180 cm tall is not something we can “measure” from
the person. Also, if we found out some other variate of the person – say
we knew the weight, and now we know also the sex – then the probability
we assign to 180 cm may increase or decrease; but the person is exactly
the same as before. Probability is not a property of the population
either. For instance, for one person from a population we may think
150 cm to be the most probable height, but for another person from the
same population we may think 180 cm to be the most probable height
instead.</p>
<p>Probability expresses the <em>information</em> we have about the
variate of a unit. This is why another researcher may have a different
probability about the same unit: because they may have different
information about that unit.</p>
<p><br />
There is a situation in which we would all agree about the probability
about a variate of a unit: when we know the <em>frequencies</em> for
that variate in the population. Suppose for instance that the population
of interest is that of penguins who lived in particular locations in
some particular years (penguins from other locations or other times are
not part of this population). The variates are the penguins’
<code>species</code> and the <code>island</code> they lived in.</p>
<p>You’re told that, as a matter of fact, 43.7% of penguins from the
<em>whole</em> population are of species <em>Adelie</em>, 20.0% of
species <em>Chinstrap</em>, and 36.3% of species <em>Gentoo</em>. Now a
penguin from that population is brought in front of you, but you can’t
see any of its characteristics. What’s your degree of belief that this
penguin is of species <em>Adelie</em>, or <em>Chinstrap</em>, or
<em>Gentoo</em>? We’d all agree, given the frequency information about
this population, to assign the probabilities of 43.7%, 20.0%, and 36.3%
to the three possibilities, for this penguin. We write this as follows:
<span class="math display">\[
\begin{aligned}
&amp;\mathrm{Pr}(\texttt{species}\!=\!\mathit{Adelie} \mid
\textsf{population frequency}) = 0.437
\\
&amp;\mathrm{Pr}(\texttt{species}\!=\!\mathit{Chinstrap} \mid
\textsf{population frequency}) = 0.200
\\
&amp;\mathrm{Pr}(\texttt{species}\!=\!\mathit{Gentoo} \mid
\textsf{population frequency}) = 0.363
\end{aligned}
\]</span> On the left side of the ‘<span class="math inline">\(\mid\)</span>’ bar we write what we’re guessing or
are unsure about. On the right side, we write the information that led
to our probability assignment; in this case, the information about the
full population. When the information behind a probability is
understood, the ‘<span class="math inline">\(\mid\)</span>’ bar and the
right side are usually omitted.</p>
<p>In this case, the highest probability is for the <em>Adelie</em>
species, but the other two possibilities cannot be excluded. The
numerical values of these probabilities are extremely important, because
they determine any kind of <strong>decision</strong> we may have to make
about our unit. This is especially true in medical decision-making,
where probabilities, combined with <strong>utilities</strong>, determine
which is the best choice that a clinician can make. Medical and clinical
decision-making, and the role of probabilities in them, are discussed
for instance in the texts by Sox &amp; al.: <a href="https://doi.org/10.1002/9781119627876"><em>Medical Decision
Making</em> (2024)</a>, by Hunink &amp; al.: <a href="https://doi.org/10.1017/CBO9781139506779"><em>Decision Making in
Health and Medicine</em> (2014)</a>, or by Weinstein &amp; Fineberg <a href="https://archive.org/details/clinicaldecision0000unse_e3n8"><em>Clinical
Decision Analysis</em> (1980)</a>.</p>
<p>The example with the penguin population can be analysed further. The
penguins in this population come from three possible
<code>island</code>s: <em>Biscoe</em>, <em>Dream</em>, and
<em>Torgersen</em>. Therefore a penguin can be of one of three species
and from one of three islands, for a total of 3 × 3 = 9 possibilities.
You’re told that, as a matter of fact, the frequencies of these nine
combinations in the whole population are as follows:</p>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"><em>Adelie</em></td>
<td align="center"><em>Chinstrap</em></td>
<td align="center"><em>Gentoo</em></td>
</tr>
<tr class="even">
<td align="center"><em>Biscoe</em></td>
<td align="center">12.6%</td>
<td align="center">1.8%</td>
<td align="center">34.0%</td>
</tr>
<tr class="odd">
<td align="center"><em>Dream</em></td>
<td align="center">17.4%</td>
<td align="center">16.5%</td>
<td align="center">1.4%</td>
</tr>
<tr class="even">
<td align="center"><em>Torgersen</em></td>
<td align="center">13.8%</td>
<td align="center">1.6%</td>
<td align="center">0.9%</td>
</tr>
</tbody>
</table>
<p>Then we’d all agree that the probability that the penguin brought to
us is of <code>species</code> <em>Gentoo</em> and from
<code>island</code> <em>Biscoe</em> would be 34.0%: <span class="math display">\[
\mathrm{Pr}(
\texttt{species}\!=\!\mathit{Gentoo} ,
\texttt{island}\!=\!\mathit{Biscoe}
\mid
\textsf{population frequency}) = 0.340
\]</span></p>
<p><br />
</p>
<p>But there’s even more interesting information in the population
frequencies above. Let’s focus on <em>Biscoe</em> island. With a quick
sum we see that 48.4% of the whole population comes from <em>Biscoe</em>
island (thus we’d assign a probability of 0.484 that our penguin comes
from that island). Dividing the frequencies above, row-wise, by the
frequencies of the respective islands (the sums of each row), we can
find the frequency of each species <em>for each particular
island</em>:</p>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"><em>Adelie</em></td>
<td align="center"><em>Chinstrap</em></td>
<td align="center"><em>Gentoo</em></td>
</tr>
<tr class="even">
<td align="center">from <em>Biscoe</em></td>
<td align="center">26.03%</td>
<td align="center">3.72%</td>
<td align="center">70.25%</td>
</tr>
<tr class="odd">
<td align="center">from <em>Dream</em></td>
<td align="center">49.29%</td>
<td align="center">46.74%</td>
<td align="center">3.97%</td>
</tr>
<tr class="even">
<td align="center">from <em>Torgersen</em></td>
<td align="center">84.66%</td>
<td align="center">9.82%</td>
<td align="center">5.52%</td>
</tr>
</tbody>
</table>
<p>We call these <strong>conditional frequencies</strong>, and we call
the group of penguins that come from <code>island</code>
<em>Biscoe</em>a <strong>subpopulation</strong> of the whole population.
The table above reports the frequencies of the three
<code>species</code> in each subpopulation.</p>
<p>Thus we also know, for instance, that 70.25% of penguins in the
subpopulation from <code>island</code> <em>Biscoe</em> are of
<code>species</code> <em>Gentoo</em>. This species is the majority in
that subpopulation – contrast this with the majority in the whole
population, which we saw was <em>Adelie</em>. Indeed, your most probable
guess about the <code>species</code> of the penguin in front of you was
<em>Adelie</em>, with 0.437 probability.</p>
<p>But suppose now someone tells you that this penguin comes from
<code>island</code> <em>Biscoe</em> (so this variate is now known to
you). Given this new piece of information, which probabilities do you
assign to the <code>species</code> of this penguin? Obviously 0.2603 for
<em>Adelie</em>, 0.0372 for <em>Chinstrap</em>, and 0.7025 for
<em>Gentoo</em>. We write this as follows: <span class="math display">\[
\begin{aligned}
&amp;\mathrm{Pr}(\texttt{species}\!=\!\mathit{Adelie} \mid
\texttt{island}\!=\!\mathit{Biscoe} ,
\textsf{population frequency}) = 0.2603
\\
&amp;\mathrm{Pr}(\texttt{species}\!=\!\mathit{Chinstrap} \mid
\texttt{island}\!=\!\mathit{Biscoe} ,
\textsf{population frequency}) = 0.0372
\\
&amp;\mathrm{Pr}(\texttt{species}\!=\!\mathit{Gentoo} \mid
\texttt{island}\!=\!\mathit{Biscoe} ,
\textsf{population frequency}) = 0.7025
\end{aligned}
\]</span> The right side of the ‘<span class="math inline">\(\mid\)</span>’ bar now reports the extra
information that the penguin comes from <code>island</code>
<em>Biscoe</em>.</p>
<p><em>(TO BE CONTINUED)</em></p>
<hr />
<hr />
<hr />
<p>(OLD TEXT)</p>
<p>We store the name of the datafile</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>dataset <span class="ot">&lt;-</span> penguins</span></code></pre></div>
<p>Here are the values for two subjects:</p>
<table style="width:100%;">
<colgroup>
<col width="5%" />
<col width="13%" />
<col width="13%" />
<col width="11%" />
<col width="11%" />
<col width="15%" />
<col width="13%" />
<col width="9%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">species</th>
<th align="left">island</th>
<th align="right">bill_len</th>
<th align="right">bill_dep</th>
<th align="right">flipper_len</th>
<th align="right">body_mass</th>
<th align="left">sex</th>
<th align="right">year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">225</td>
<td align="left">Gentoo</td>
<td align="left">Biscoe</td>
<td align="right">48.2</td>
<td align="right">15.6</td>
<td align="right">221</td>
<td align="right">5100</td>
<td align="left">male</td>
<td align="right">2008</td>
</tr>
<tr class="even">
<td align="left">127</td>
<td align="left">Adelie</td>
<td align="left">Torgersen</td>
<td align="right">38.8</td>
<td align="right">17.6</td>
<td align="right">191</td>
<td align="right">3275</td>
<td align="left">female</td>
<td align="right">2009</td>
</tr>
<tr class="odd">
<td align="left">315</td>
<td align="left">Chinstrap</td>
<td align="left">Dream</td>
<td align="right">46.9</td>
<td align="right">16.6</td>
<td align="right">192</td>
<td align="right">2700</td>
<td align="left">female</td>
<td align="right">2008</td>
</tr>
<tr class="even">
<td align="left">189</td>
<td align="left">Gentoo</td>
<td align="left">Biscoe</td>
<td align="right">42.6</td>
<td align="right">13.7</td>
<td align="right">213</td>
<td align="right">4950</td>
<td align="left">female</td>
<td align="right">2008</td>
</tr>
<tr class="odd">
<td align="left">271</td>
<td align="left">Gentoo</td>
<td align="left">Biscoe</td>
<td align="right">47.2</td>
<td align="right">13.7</td>
<td align="right">214</td>
<td align="right">4925</td>
<td align="left">female</td>
<td align="right">2009</td>
</tr>
</tbody>
</table>
</div>
<div id="natural-vs-controlled-or-biased-variates" class="section level3">
<h3>“Natural” vs controlled or “biased” variates</h3>
</div>
</div>
<div id="metadata" class="section level2">
<h2>Metadata</h2>
<p>Let’s load the package:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">library</span>(inferno)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode r fold-hide"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="do">## metadatatemplate(data = datafile, file = &#39;temp_metadata&#39;)</span></span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>metadatafile <span class="ot">&lt;-</span> <span class="st">&#39;meta_toydata.csv&#39;</span></span></code></pre></div>
<p>The metadata are as follows; <code>NA</code> indicate empty
fields:</p>
<table>
<colgroup>
<col width="33%" />
<col width="9%" />
<col width="7%" />
<col width="8%" />
<col width="8%" />
<col width="10%" />
<col width="10%" />
<col width="5%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">name</th>
<th align="left">type</th>
<th align="right">datastep</th>
<th align="right">domainmin</th>
<th align="right">domainmax</th>
<th align="left">minincluded</th>
<th align="left">maxincluded</th>
<th align="left">V1</th>
<th align="left">V2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">TreatmentGroup</td>
<td align="left">nominal</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">NR</td>
<td align="left">Placebo</td>
</tr>
<tr class="even">
<td align="left">Sex</td>
<td align="left">nominal</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">Female</td>
<td align="left">Male</td>
</tr>
<tr class="odd">
<td align="left">Age</td>
<td align="left">continuous</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Anamnestic.Loss.of.smell</td>
<td align="left">nominal</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">No</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">History.of.REM.Sleep.Behaviour.Disorder</td>
<td align="left">nominal</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">No</td>
<td align="left">Yes</td>
</tr>
<tr class="even">
<td align="left">MDS.UPDRS..Subsection.III.V1</td>
<td align="left">ordinal</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">132</td>
<td align="left">yes</td>
<td align="left">yes</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">diff.MDS.UPRS.III</td>
<td align="left">ordinal</td>
<td align="right">1</td>
<td align="right">-132</td>
<td align="right">132</td>
<td align="left">yes</td>
<td align="left">yes</td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p><em>(More to be written here!)</em></p>
</div>
<div id="learning" class="section level2">
<h2>Learning</h2>
<p><span class="math display">\[
\mathrm{Pr}(Y = y \:\vert\: X = x, \mathrm{data})
\]</span> As the notation above indicates, <em>these probabilities also
depend on the <span class="math inline">\(\mathrm{data}\)</span> already
observed</em>. They are usually called “posterior probabilities”.</p>
<p>We need to prepare the software to perform calculations of posterior
probabilities given the observed data. In machine learning an analogous
process is called “learning”. For this reason the function that achieves
this is called <code>learn()</code>. It requires at least three
arguments:</p>
<ul>
<li><code>data</code>, which can be given as a path to the
<code>csv</code> file containing the data</li>
<li><code>metadata</code>, which can also be given as a path to the
metadata file</li>
<li><code>outputdir</code>: the name of the directory where the output
should be saved.</li>
</ul>
<p>It may be useful to specify two more arguments:</p>
<ul>
<li><code>seed</code>: the seed for the random-number generator, to
ensure reproducibility</li>
<li><code>parallel</code>: the number of CPUs to use for the
computation</li>
</ul>
<p>Alternatively you can set the seed with <code>set.seed()</code>, and
start a set of parallel workers with the
<code>parallel::makeCluster()</code> and
<code>doParallel::registerDoParallel()</code> commands.</p>
<p>The “learning” computation can take tens of minutes, or hours, or
even days depending on the number of variates and data in your inference
problem. The <code>learn()</code> function outputs various messages on
how the computation is proceeding. As an example:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>learnt <span class="ot">&lt;-</span> <span class="fu">learn</span>(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="at">data =</span> datafile,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    <span class="at">metadata =</span> metadatafile,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    <span class="at">outputdir =</span> <span class="st">&#39;parkinson_computations&#39;</span>,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">16</span>,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    <span class="at">parallel =</span> <span class="dv">12</span>)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt; Registered doParallelSNOW with 12 workers</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt;</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt; Using 30 datapoints</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt; Calculating auxiliary metadata</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt;</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt; **************************</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt; Saving output in directory</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">#&gt; parkinson_computations</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="co">#&gt; **************************</span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="co">#&gt; Starting Monte Carlo sampling of 3600 samples by 60 chains</span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="co">#&gt; in a space of 703 (effectively 6657) dimensions.</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a><span class="co">#&gt; Using 12 cores: 60 samples per chain, 5 chains per core.</span></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a><span class="co">#&gt; Core logs are being saved in individual files.</span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a><span class="co">#&gt;</span></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a><span class="co">#&gt; C-compiling samplers appropriate to the variates (package Nimble)</span></span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a><span class="co">#&gt; this can take tens of minutes with many data or variates.</span></span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a><span class="co">#&gt; Please wait...</span></span></code></pre></div>
</div>
<div id="drawing-inferences" class="section level2">
<h2>Drawing inferences</h2>
<p><em>(TO BE CONTINUED)</em></p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
